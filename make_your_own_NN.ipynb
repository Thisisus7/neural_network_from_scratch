{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "38d755bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "# plot graphics in the notebook, not in a separate external window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "607a8d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.zeros([3,2])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c49979b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  2.],\n",
       "       [ 9.,  0.],\n",
       "       [ 0., 12.]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0,0] = 1\n",
    "a[0,1] = 2\n",
    "a[1,0] = 9\n",
    "a[2,1] = 12\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1ad15f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[2,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "da7734ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2465a6eb400>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(a, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443542a7",
   "metadata": {},
   "source": [
    "## objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "34f30506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "woof!\n",
      "woof!\n",
      "dog name is Mutley\n",
      "dog tempature is 37\n",
      "dog name is mut\n",
      "dog tempature is 45\n"
     ]
    }
   ],
   "source": [
    "# class for a dog object\n",
    "class dog:\n",
    "    \n",
    "    # initiation method with internal data\n",
    "    def __init__(self, petname, temp):\n",
    "        self.name = petname\n",
    "        self.tempature = temp\n",
    "    \n",
    "    # get status\n",
    "    def status(self):\n",
    "        print(\"dog name is\", self.name)\n",
    "        print(\"dog tempature is\", self.tempature)\n",
    "        \n",
    "    # set tempature\n",
    "    def setTempature(self, temp): # you can change the object's tempature at any time after you created the object.\n",
    "        self.tempature = temp;\n",
    "        pass\n",
    "        \n",
    "    # dog can bark()\n",
    "    def bark(self):\n",
    "        print('woof!')\n",
    "        pass\n",
    "    pass\n",
    "\n",
    "# create 2 objects\n",
    "sizzles = dog('Sizzles', 39)\n",
    "mutley = dog('Mutley', 37)\n",
    "sizzles.bark() # method\n",
    "mutley.bark()\n",
    "mutley.status()\n",
    "mutley.__init__('mut',40)\n",
    "mutley.setTempature(45)\n",
    "mutley.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27977426",
   "metadata": {},
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7db5abf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.special\n",
    "import scipy.misc\n",
    "# helper to load data from PNG image files\n",
    "import imageio\n",
    "# glob helps select multiple files using patterns\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f4a717ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network class definition\n",
    "class neuralNetwork:\n",
    "    \n",
    "    # initialise the neural network\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        # set the number of nodes in each input, hidden, output layer\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "        \n",
    "        # link weight matrices, wih and who\n",
    "        # mean; standard deviation; shape\n",
    "        self.wih = np.random.normal(0.0, pow(self.hnodes, -0.5), (self.hnodes, self.inodes))\n",
    "        self.who = np.random.normal(0.0, pow(self.onodes, -0.5), (self.onodes, self.hnodes))\n",
    "        \n",
    "        # learning rate\n",
    "        self.lr = learningrate\n",
    "        \n",
    "        # activation function is the sigmoid function\n",
    "        # lambda: define a function, name is before '='\n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "    \n",
    "    # train the neural network\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = np.array(inputs_list, ndmin=2).T\n",
    "        targets = np.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "        # calculate signals emerging fron hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = np.dot(self.who, hidden_outputs)\n",
    "        # calculate signals emerging fron hidden layer\n",
    "        final_outputs = self.activation_function(final_inputs) \n",
    "        \n",
    "        # output layer error is the (target - actual)\n",
    "        output_errors = targets - final_outputs\n",
    "        # hidden layer error is the output_errors, split by weights, recombined at hidden nodes\n",
    "        hidden_errors = np.dot(self.who.T, output_errors)\n",
    "        \n",
    "        # update the weights for the links between the hidden and output layers\n",
    "        self.who += self.lr * np.dot((output_errors * final_outputs * (1.0 - final_outputs)), np.transpose(hidden_outputs))\n",
    "        # update the weights for the links between the input and hidden layers\n",
    "        self.wih += self.lr * np.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), np.transpose(inputs))\n",
    "      \n",
    "    # query the neural network\n",
    "    def query(self, inputs_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = np.array(inputs_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "        # calculate signals emerging fron hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = np.dot(self.who, hidden_outputs)\n",
    "        # calculate signals emerging fron hidden layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        return final_outputs\n",
    "    \n",
    "    # backquery the neural network\n",
    "    # we'll use the same termnimology to each item, \n",
    "    # eg target are the values at the right of the network, albeit used as input\n",
    "    # eg hidden_output is the signal to the right of the middle nodes\n",
    "    def backquery(self, targets_list):\n",
    "        # transpose the targets list to a vertical array\n",
    "        final_outputs = numpy.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        # calculate the signal into the final output layer\n",
    "        final_inputs = self.inverse_activation_function(final_outputs)\n",
    "\n",
    "        # calculate the signal out of the hidden layer\n",
    "        hidden_outputs = numpy.dot(self.who.T, final_inputs)\n",
    "        # scale them back to 0.01 to .99\n",
    "        hidden_outputs -= numpy.min(hidden_outputs)\n",
    "        hidden_outputs /= numpy.max(hidden_outputs)\n",
    "        hidden_outputs *= 0.98\n",
    "        hidden_outputs += 0.01\n",
    "        \n",
    "        # calculate the signal into the hidden layer\n",
    "        hidden_inputs = self.inverse_activation_function(hidden_outputs)\n",
    "        \n",
    "        # calculate the signal out of the input layer\n",
    "        inputs = numpy.dot(self.wih.T, hidden_inputs)\n",
    "        # scale them back to 0.01 to .99\n",
    "        inputs -= numpy.min(inputs)\n",
    "        inputs /= numpy.max(inputs)\n",
    "        inputs *= 0.98\n",
    "        inputs += 0.01\n",
    "        \n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8047aa50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance =  0.9712\n"
     ]
    }
   ],
   "source": [
    "# number of input, hidden and output nodes\n",
    "input_nodes = 784  # 28*28 pixels\n",
    "hidden_nodes = 250  # less than 784, but not too small(there is no perfect method for choosing hidden nodes and layer)\n",
    "output_nodes = 10  # 10 labels\n",
    "\n",
    "# learning rate\n",
    "learning_rate = 0.1\n",
    "\n",
    "# create instance of neural network\n",
    "n = neuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate)\n",
    "\n",
    "# loading the mnist training data CSV file into a list\n",
    "training_data_file = open(\"E:\\download\\MNIST\\mnist_train.csv\", 'r') # r:read only\n",
    "training_data_list = training_data_file.readlines() # for big file, don't usereadlines()(reads the entire file into memory)\n",
    "training_data_file.close() # good habit\n",
    "\n",
    "# train the neural network\n",
    "\n",
    "# epochs is the number of times the training data set is used for training\n",
    "epoch = 5\n",
    "\n",
    "for e in range(epoch):\n",
    "    # go through all records in the training data set\n",
    "    for record in training_data_list:\n",
    "        # split the record by the ',' commas\n",
    "        all_values = record.split(',')\n",
    "        # scale and shift the inputs to range 0.01 to 1.00\n",
    "        inputs = (np.asfarray(all_values[1:]) / 255 * 0.99) + 0.01\n",
    "        # create the target output values (all 0.01, except the desired label which is 0.99)\n",
    "        targets = np.zeros(output_nodes) + 0.01\n",
    "        # all values[0] is the target label for this record\n",
    "        targets[int(all_values[0])] = 0.99\n",
    "        n.train(inputs, targets)\n",
    "    \n",
    "# load the mnist test data CSV file into a list\n",
    "test_data_file = open(\"E:\\download\\MNIST\\mnist_test.csv\", 'r')\n",
    "test_data_list = test_data_file.readlines()\n",
    "test_data_file.close()\n",
    "\n",
    "# test the neural network\n",
    "\n",
    "# scorecard for how well the network performs, initially empty\n",
    "scorecard = []\n",
    "\n",
    "# go through all the records in the test data set\n",
    "for record in test_data_list:\n",
    "    # split the record by the ',' commas\n",
    "    all_values = record.split(',')\n",
    "    # correct answer is the first value\n",
    "    correct_label = int(all_values[0])\n",
    "    # print(correct_label, \"correct label\")\n",
    "    # scale and shift the inputs to range 0.01 to 1.00\n",
    "    inputs = (np.asfarray(all_values[1:]) / 255 * 0.99) + 0.01\n",
    "    # query the network\n",
    "    outputs = n.query(inputs)\n",
    "    # the index of the highest value corresponds to the label \n",
    "    label = np.argmax(outputs)\n",
    "    # print(label, \"network's answer\")\n",
    "    # append correct or incorrect to list\n",
    "    if label == correct_label:\n",
    "        # network's annswer matches correct answer, add 1 to scorecard\n",
    "        scorecard.append(1)\n",
    "    else:\n",
    "        # network's answer doesn't match correct answer, add 0 to scorecard\n",
    "        scorecard.append(0)\n",
    "        \n",
    "# print(scorecard)\n",
    "# calculate the performance score, the fraction of correct answers \n",
    "scorecard_array = np.asarray(scorecard)\n",
    "print(\"performance = \", scorecard_array.sum() / scorecard_array.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1ce57732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2465b7104f0>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot\n",
    "all_values = data_list[0].split(',') # delete the comma\n",
    "# [1:] take all except the 1st element of this list\n",
    "# .asfarray: convert text strings into real numbers\n",
    "# reshape: convert 784 to 28*28\n",
    "image_array = np.asfarray(all_values[1:]).reshape((28,28)) \n",
    "plt.imshow(image_array, cmap='Greys', interpolation='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "daa96ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2465b775130>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get the first test record\n",
    "all_values = test_data_list[0].split(',')\n",
    "# print the label\n",
    "print(all_values[0])\n",
    "\n",
    "image_array = np.asfarray(all_values[1:]).reshape((28,28))\n",
    "plt.imshow(image_array, cmap='Greys', interpolation='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "52f42260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0204121 ],\n",
       "       [0.00433313],\n",
       "       [0.00243854],\n",
       "       [0.0052142 ],\n",
       "       [0.0023806 ],\n",
       "       [0.00994541],\n",
       "       [0.0157581 ],\n",
       "       [0.9871998 ],\n",
       "       [0.00454907],\n",
       "       [0.02647128]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.query((np.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ad9739",
   "metadata": {},
   "source": [
    "## use your own images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "cb097a77",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'scipy.misc' has no attribute 'imread'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [121]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# image_file_name\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# get data from PNG or JPG\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# flatten:turns the image into simple array of float numbers; also flatten color values into grey scale\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m img_array \u001b[38;5;241m=\u001b[39m \u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmisc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m(image_file_name, flatten\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# reshape the array from 28*28 square into a longlist of values\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# 255- : image(0:black, 255:white); MNIST(0:white, 255:black)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m img_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255.0\u001b[39m \u001b[38;5;241m-\u001b[39m img_array\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m784\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'scipy.misc' has no attribute 'imread'"
     ]
    }
   ],
   "source": [
    "# image_file_name\n",
    "# get data from PNG or JPG\n",
    "# flatten:turns the image into simple array of float numbers; also flatten color values into grey scale\n",
    "img_array = scipy.misc.imread(image_file_name, flatten=True)  \n",
    "\n",
    "# reshape the array from 28*28 square into a longlist of values\n",
    "# 255- : image(0:black, 255:white); MNIST(0:white, 255:black)\n",
    "img_data = 255.0 - img_array.reshape(784)\n",
    "# range from 0.01 to 1.00\n",
    "img_data = (img_data / 255.0 / 0.99) + 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a387ab8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'glob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [122]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m our_own_dataset \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# load the png image data as test data set\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_file_name \u001b[38;5;129;01min\u001b[39;00m \u001b[43mglob\u001b[49m\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmy_own_images/2828_my_own_?.png\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m      6\u001b[0m     \n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# use the filename to set the correct label\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(image_file_name[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m])\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# load image data from png files into an array\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'glob' is not defined"
     ]
    }
   ],
   "source": [
    "# our own image test data set\n",
    "our_own_dataset = []\n",
    "\n",
    "# load the png image data as test data set\n",
    "for image_file_name in glob.glob('my_own_images/2828_my_own_?.png'):\n",
    "    \n",
    "    # use the filename to set the correct label\n",
    "    label = int(image_file_name[-5:-4])\n",
    "    \n",
    "    # load image data from png files into an array\n",
    "    print (\"loading ... \", image_file_name)\n",
    "    img_array = imageio.imread(image_file_name, as_gray=True)\n",
    "    \n",
    "    # reshape from 28x28 to list of 784 values, invert values\n",
    "    img_data  = 255.0 - img_array.reshape(784)\n",
    "    \n",
    "    # then scale data to range from 0.01 to 1.0\n",
    "    img_data = (img_data / 255.0 * 0.99) + 0.01\n",
    "    print(numpy.min(img_data))\n",
    "    print(numpy.max(img_data))\n",
    "    \n",
    "    # append label and image data  to test data set\n",
    "    record = numpy.append(label,img_data)\n",
    "    our_own_dataset.append(record)\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "debc0ec7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'matplotlib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [123]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# plot image\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[43mmatplotlib\u001b[49m\u001b[38;5;241m.\u001b[39mpyplot\u001b[38;5;241m.\u001b[39mimshow(our_own_dataset[item][\u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m28\u001b[39m,\u001b[38;5;241m28\u001b[39m), cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGreys\u001b[39m\u001b[38;5;124m'\u001b[39m, interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# correct answer is first value\u001b[39;00m\n\u001b[0;32m     10\u001b[0m correct_label \u001b[38;5;241m=\u001b[39m our_own_dataset[item][\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'matplotlib' is not defined"
     ]
    }
   ],
   "source": [
    "# test the neural network with our own images\n",
    "\n",
    "# record to test\n",
    "item = 2\n",
    "\n",
    "# plot image\n",
    "matplotlib.pyplot.imshow(our_own_dataset[item][1:].reshape(28,28), cmap='Greys', interpolation='None')\n",
    "\n",
    "# correct answer is first value\n",
    "correct_label = our_own_dataset[item][0]\n",
    "# data is remaining values\n",
    "inputs = our_own_dataset[item][1:]\n",
    "\n",
    "# query the network\n",
    "outputs = n.query(inputs)\n",
    "print (outputs)\n",
    "\n",
    "# the index of the highest value corresponds to the label\n",
    "label = numpy.argmax(outputs)\n",
    "print(\"network says \", label)\n",
    "# append correct or incorrect to list\n",
    "if (label == correct_label):\n",
    "    print (\"match!\")\n",
    "else:\n",
    "    print (\"no match!\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f471f511",
   "metadata": {},
   "source": [
    "## backquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c7124209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'neuralNetwork' object has no attribute 'backquery'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [129]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(targets)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# get image data\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m image_data \u001b[38;5;241m=\u001b[39m \u001b[43mn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackquery\u001b[49m(targets)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# plot image data\u001b[39;00m\n\u001b[0;32m     15\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(image_data\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m28\u001b[39m,\u001b[38;5;241m28\u001b[39m), cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGreys\u001b[39m\u001b[38;5;124m'\u001b[39m, interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'neuralNetwork' object has no attribute 'backquery'"
     ]
    }
   ],
   "source": [
    "# run the network backwards, given a label, see what image it produces\n",
    "\n",
    "# label to test\n",
    "label = 0\n",
    "# create the output signals for this label\n",
    "targets = np.zeros(output_nodes) + 0.01\n",
    "# all_values[0] is the target label for this record\n",
    "targets[label] = 0.99\n",
    "print(targets)\n",
    "\n",
    "# get image data\n",
    "image_data = n.backquery(targets)\n",
    "\n",
    "# plot image data\n",
    "plt.imshow(image_data.reshape(28,28), cmap='Greys', interpolation='None')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7c17bd",
   "metadata": {},
   "source": [
    "## rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae576f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create rotate variations\n",
    "# rotated anticlockwise by 10 degrees\n",
    "# cval: fill 0.01 in array elements because they didn't exist in the original image\n",
    "inputs_plus10_img = scipy.ndimage.interpolation.rotate(scaled_input_reshape(28,28), 10, cval=0.01, reshape=False)\n",
    "# rotated clockwise by 10 degrees\n",
    "inputs_plus10_img = scipy.ndimage.interpolation.rotate(scaled_input_reshape(28,28), -10, cval=0.01, reshape=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
